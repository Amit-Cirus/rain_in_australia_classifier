{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "from scipy.stats import skew, kurtosis\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "os.environ['KAGGLE_CONFIG_DIR'] = r'C:\\Users\\amitb\\.kaggle'\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "print(\"Kaggle authentication successful!\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data = pd.read_csv(r\"C:\\code_projects\\applied_DS\\rain_in_australia_classifier\\weatherAUS.csv\")\n",
    "print(f'There are {data.shape[0]} samples within the dataset')\n",
    "data.head(10)"
   ],
   "id": "84dca29750fd9db7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data.describe(include='all')",
   "id": "7a93a3f4d1557163",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "numeric_cols = data.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "\n",
    "for numeric_col in numeric_cols:\n",
    "    data[numeric_col] = data[numeric_col].astype(float)\n",
    "\n",
    "\n",
    "categorical_cols = data.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "categorical_cols.remove('Date')\n",
    "\n",
    "for categorical_col in categorical_cols:\n",
    "    data[categorical_col] = data[categorical_col].astype('category')\n",
    "\n",
    "data['Date'] = data['Date'].astype('datetime64[ns]')\n",
    "\n",
    "data.dtypes"
   ],
   "id": "45e2cd94e061c13c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Handling missing values\n",
   "id": "84aa30a8fccc495f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# checking NA\n",
    "\n",
    "mising_values_col_sum = pd.Series(data.isnull().sum(), name='% of NA').apply(lambda x: f\"{(x / data.shape[0] * 100):.2f}\").astype('float').sort_values(ascending=False)\n",
    "mising_values_col_sum"
   ],
   "id": "4a6ca2c6656fb336",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "features = ['Sunshine', 'Evaporation', 'Cloud3pm','Cloud9am','Pressure9am','Pressure3pm']\n",
    "\n",
    "n_features = len(features)\n",
    "fig, axes = plt.subplots(n_features, 1, figsize=(8, 4*n_features))  # vertical layout\n",
    "\n",
    "for i, feature in enumerate(features):\n",
    "    axes[i].hist(data[feature], bins=20, color='skyblue', edgecolor='black')\n",
    "    axes[i].set_title(f'{feature} | % missing values {mising_values_col_sum[feature]}')\n",
    "    axes[i].set_xlabel(feature)\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "bf85fff9c644ad00",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# detect features with/without normal distribution\n",
    "\n",
    "\n",
    "results = {'feature': [], 'Skewness': [], 'Excess_Kurtosis': []}\n",
    "\n",
    "for column in features:\n",
    "    x = data[column].dropna()\n",
    "    results['feature'].append(column)\n",
    "    results['Skewness'].append(skew(x))\n",
    "    results['Excess_Kurtosis'].append(kurtosis(x))\n",
    "\n",
    "pd.DataFrame(results)\n",
    "\n"
   ],
   "id": "c6bf2ea364152bba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# use median to imput features with normal distribution\n",
    "\n",
    "results = pd.DataFrame(results)\n",
    "\n",
    "features_to_imput_with_median = [\n",
    "    f for f, skew, kurt in zip(results.feature, results.Skewness, results.Excess_Kurtosis)\n",
    "    if abs(skew) < 0.1 and abs(kurt) < 0.5\n",
    "]\n",
    "\n",
    "for feature in features_to_imput_with_median:\n",
    "    feature_median = data[feature].median()\n",
    "    data[feature] = data[feature].fillna(feature_median)"
   ],
   "id": "24611ba1e53b205e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#fillna with random choise to preserves the skewed distribution and extreme values (for Evaporation which dosen't have bi-mode / normal dist)\n",
    "\n",
    "observed = data['Evaporation'].dropna()\n",
    "data['Evaporation'] = data['Evaporation'].fillna(np.random.choice(observed))\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(data['Evaporation'].dropna(), bins=30, color='skyblue', edgecolor='black')\n",
    "plt.title('Histogram of Evaporation')\n",
    "plt.xlabel('Evaporation')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.show()"
   ],
   "id": "3a66b8f40861815b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Predict cluster for missing values randomly based on cluster weights for features with bi-modal distribution\n",
    "\n",
    "bi_mode_features = ['Cloud3pm', 'Cloud9am', 'Sunshine']\n",
    "\n",
    "for col in bi_mode_features:\n",
    "    observed = data[col].dropna().values.reshape(-1,1)\n",
    "\n",
    "    # Fit 2-component GMM\n",
    "    gmm = GaussianMixture(n_components=2, random_state=42)\n",
    "    gmm.fit(observed)\n",
    "\n",
    "    # Missing indices\n",
    "    missing_idx = data[col].isna()\n",
    "    n_missing = missing_idx.sum()\n",
    "\n",
    "    # Assign clusters to missing values\n",
    "    sampled_cluster = np.random.choice(2, size=n_missing, p=gmm.weights_)\n",
    "\n",
    "    # Get cluster labels for observed values\n",
    "    cluster_labels = gmm.predict(observed)\n",
    "\n",
    "    # Precompute cluster-wise observed values for faster sampling\n",
    "    cluster_values = [observed[cluster_labels == k].flatten() for k in range(2)]\n",
    "\n",
    "    # Vectorized imputation\n",
    "    imputed_values = np.array([np.random.choice(cluster_values[k]) for k in sampled_cluster])\n",
    "\n",
    "    data.loc[missing_idx, col] = imputed_values\n",
    "\n",
    "\n",
    "missing_after_GaussianMixture = pd.Series(data[bi_mode_features].isna().sum(),name='% missing')\n",
    "missing_after_GaussianMixture\n",
    "\n",
    "n_features = len(bi_mode_features)\n",
    "\n",
    "# fig, axes = plt.subplots(n_features, 1, figsize=(8, 4*n_features))  # vertical layout\n",
    "#\n",
    "# for i, feature in enumerate(bi_mode_features):\n",
    "#     axes[i].hist(data[feature], bins=20, color='skyblue', edgecolor='black')\n",
    "#     axes[i].set_title(f'{feature} | % missing values: {missing_after_GaussianMixture[feature]}')\n",
    "#     axes[i].set_xlabel(feature)\n",
    "#     axes[i].set_ylabel('Frequency')\n",
    "#\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ],
   "id": "6098c6ecea1189d0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#final review of NA values info (for these features with less than 10% missing values\n",
    "\n",
    "cols_na = pd.Series(data.isnull().sum(), name='% of NA').apply(lambda x: f\"{(x / data.shape[0] * 100):.2f}\").astype('float').sort_values(ascending=False)\n",
    "\n",
    "filtered = cols_na[cols_na > 0]\n",
    "\n",
    "features = filtered.index.tolist()\n",
    "\n",
    "results = {'feature': [], 'Skewness': [], 'Excess_Kurtosis': []}\n",
    "\n",
    "for column in features:\n",
    "    if column in numeric_cols:\n",
    "        x = data[column].dropna()\n",
    "        results['feature'].append(column)\n",
    "        results['Skewness'].append(skew(x))\n",
    "        results['Excess_Kurtosis'].append(kurtosis(x))\n",
    "\n",
    "data_results = pd.DataFrame(results)"
   ],
   "id": "8830dd04958afd63",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data_results",
   "id": "ec8ace50fdf351ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# features_numeric = [x for x in filtered.index.tolist() if x in numeric_cols]\n",
    "#\n",
    "# n_features = len(features_numeric)\n",
    "# fig, axes = plt.subplots(n_features, 1, figsize=(8, 4*n_features))  # vertical layout\n",
    "#\n",
    "# for i, feature in enumerate(features_numeric):\n",
    "#     axes[i].hist(data[feature], bins=20, color='skyblue', edgecolor='black')\n",
    "#     axes[i].set_title(f'{feature}')\n",
    "#     axes[i].set_xlabel(f'{feature}')\n",
    "#     axes[i].set_ylabel('Frequency')\n",
    "#\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ],
   "id": "6cadd37bb391983d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "normal_features = data_results[\n",
    "    (data_results['Skewness'].abs() < 0.1) & (data_results['Excess_Kurtosis'].abs() < 0.5)\n",
    "]['feature'].tolist()\n",
    "\n",
    "skewed_features = data_results[\n",
    "    ~data_results['feature'].isin(normal_features)\n",
    "]['feature'].tolist()\n",
    "\n",
    "# Impute normal-ish features with mean\n",
    "for feature in normal_features:\n",
    "    data[feature] = data[feature].fillna(data[feature].mean())\n",
    "\n",
    "# Impute highly skewed features with median\n",
    "for feature in skewed_features:\n",
    "    data[feature] = data[feature].fillna(data[feature].median())"
   ],
   "id": "d6807458f5c8cc66",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "nan_results = pd.Series(data.isnull().sum(), name='% of NA').apply(lambda x: f\"{(x / data.shape[0] * 100):.2f}\").astype('float').sort_values(ascending=False)\n",
    "cols_to_imput = nan_results[nan_results.values >0].index\n",
    "data[cols_to_imput].info()"
   ],
   "id": "501ccaf058504217",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data[cols_to_imput].describe(include='all')\n",
   "id": "dc0ee53eda17363a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "wind_cols = [x for x in cols_to_imput if 'Wind' in str(x)]\n",
    "wind_cols"
   ],
   "id": "810401d7a099d142",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for col in wind_cols:\n",
    "    data[col]= data[col].fillna(data[col].mode()[0])"
   ],
   "id": "f1c7c76b42de4673",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Adding Features",
   "id": "a7024d360bafca16"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#create categorical Season feature\n",
    "\n",
    "def get_season(date):\n",
    "    day = date.day\n",
    "    month = date.month\n",
    "\n",
    "    if (month == 12 and day >= 21) or (month <= 3 and (month < 3 or day <= 21)):\n",
    "        return 'Summer'\n",
    "    elif (month == 3 and day >= 22) or (month <= 6 and (month < 6 or day <= 21)):\n",
    "        return 'Autumn'\n",
    "    elif (month == 6 and day >= 22) or (month <= 9 and (month < 9 or day <= 21)):\n",
    "        return 'Winter'\n",
    "    elif (month == 9 and day >= 22) or (month <= 12 and (month < 12 or day <= 20)):\n",
    "        return 'Spring'\n",
    "\n",
    "data['Season'] = data['Date'].map(get_season)\n",
    "data['Season'] = data['Season'].astype('category')\n",
    "\n",
    "data = pd.get_dummies(data, columns=[\"Season\"], drop_first=False)\n"
   ],
   "id": "fe4d0aa803d6a43c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "binary_dict = {'No': 0, 'Yes':1}\n",
    "\n",
    "data['RainToday']=data['RainToday'].map(binary_dict)\n",
    "data['RainTomorrow']=data['RainTomorrow'].map(binary_dict)"
   ],
   "id": "fc7542e749e132c0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#extract COSIN for day, month and year\n",
    "\n",
    "data[\"day_of_week\"] = data[\"Date\"].dt.weekday      # 0 = Monday\n",
    "data[\"month\"] = data[\"Date\"].dt.month\n",
    "data[\"day_of_year\"] = data[\"Date\"].dt.dayofyear\n",
    "data[\"year\"] = data[\"Date\"].dt.year\n",
    "\n",
    "# Cyclical encoding\n",
    "data[\"day_of_week_sin\"] = np.sin(2 * np.pi * data[\"day_of_week\"] / 7)\n",
    "data[\"day_of_week_cos\"] = np.cos(2 * np.pi * data[\"day_of_week\"] / 7)\n",
    "\n",
    "data[\"month_sin\"] = np.sin(2 * np.pi * data[\"month\"] / 12)\n",
    "data[\"month_cos\"] = np.cos(2 * np.pi * data[\"month\"] / 12)\n",
    "\n",
    "data[\"day_of_year_sin\"] = np.sin(2 * np.pi * data[\"day_of_year\"] / 365)\n",
    "data[\"day_of_year_cos\"] = np.cos(2 * np.pi * data[\"day_of_year\"] / 365)\n",
    "\n",
    "data.drop(columns='Date',inplace=True)"
   ],
   "id": "ba0c932f19d25a7a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data.dropna(subset='RainTomorrow',inplace=True,axis=0)\n",
    "data['RainTomorrow'].isna().sum()"
   ],
   "id": "65b202a9ccd6ef44",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data = pd.get_dummies(data, columns=[\"RainToday\"], drop_first=False)",
   "id": "a87393c194ce8938",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Label encoing for categorical columns\n",
    "\n",
    "Location = LabelEncoder()\n",
    "data['Location'] = Location.fit_transform(data['Location'])\n",
    "\n",
    "wind_categories = sorted(data[wind_cols[0]].unique())  # replace 'wind1' with one of the 3\n",
    "le_wind = LabelEncoder()\n",
    "le_wind.fit(wind_categories)\n",
    "\n",
    "for col in wind_cols:\n",
    "    data[col + '_encoded'] = le_wind.transform(data[col])\n",
    "\n",
    "data.drop(columns=['WindDir9am','WindGustDir','WindDir3pm'], inplace=True)"
   ],
   "id": "b463a3225d4f1947",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data.head()",
   "id": "6103f38c3d2330c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# exclude outlayers",
   "id": "942b7f03ba0575ea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "numeric_df = data[['MinTemp', 'MaxTemp', 'Rainfall', 'Evaporation', 'Sunshine','WindGustSpeed','WindSpeed9am','WindSpeed3pm',\n",
    "       'Humidity9am', 'Humidity3pm', 'Pressure9am', 'Pressure3pm','Temp9am', 'Temp3pm']]\n",
    "\n",
    "Q1 = numeric_df.quantile(0.25)\n",
    "Q3 = numeric_df.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Detect outliers\n",
    "outliers = (numeric_df < (Q1 - 1.5 * IQR)) | (numeric_df > (Q3 + 1.5 * IQR))\n",
    "\n",
    "for col in numeric_df.columns:\n",
    "    Q1 = data[col].quantile(0.25)\n",
    "    Q3 = data[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - 1.5 * IQR\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "\n",
    "    # Clip values outside IQR bounds\n",
    "    data[col] = data[col].clip(lower=lower, upper=upper)"
   ],
   "id": "824ba556f28cc47c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data.head()",
   "id": "8679a1e6bfddbf03",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# numeric_columns = [\"MinTemp\",\"Rainfall\",\"MaxTemp\",\"WindGustSpeed\",\"WindSpeed9am\",\"WindSpeed3pm\",\"Humidity9am\",\"Humidity3pm\",\"Temp9am\",\"Temp3pm\",\"Pressure9am\",\"Pressure3pm\"]\n",
    "# scaler = StandardScaler()\n",
    "# data[numeric_columns] = scaler.fit_transform(data[numeric_columns])"
   ],
   "id": "d7561f20d9469ec9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# spliting",
   "id": "82120951f7d950a0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "x = data.drop(columns='RainTomorrow')\n",
    "y = data['RainTomorrow']"
   ],
   "id": "7636998e710801ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "y.value_counts()",
   "id": "826c7039dc436e6a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, stratify=y, random_state = 42)\n"
   ],
   "id": "7ffbc61debe7bce6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#detect columns for standard scaler\n",
    "\n",
    "cols_for_scaler = ['MinTemp', 'MaxTemp', 'Rainfall', 'Evaporation', 'Sunshine',\"WindGustSpeed\",\"WindSpeed9am\",\"WindSpeed3pm\",\n",
    "       'Humidity9am', 'Humidity3pm', 'Pressure9am', 'Pressure3pm','Temp9am', 'Temp3pm']\n",
    "\n",
    "X_train_pro = X_train[cols_for_scaler]\n",
    "\n",
    "X_test_pro = X_test[cols_for_scaler]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_pro)\n",
    "\n",
    "# Apply same scaler to test data\n",
    "X_test_scaled = scaler.transform(X_test_pro)\n",
    "\n",
    "X_train[cols_for_scaler] = X_train_scaled\n",
    "X_test[cols_for_scaler] = X_test_scaled\n"
   ],
   "id": "8dee35caf2a5fe8f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train, y_train  = smote.fit_resample(X_train, y_train)"
   ],
   "id": "ba3610c56567d81e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# ---------------------------------------------------------\n",
    "# Stratified KFold + GridSearch\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "xgb = XGBClassifier(eval_metric=\"logloss\",\n",
    "                    random_state=42,\n",
    "                    enable_categorical=True\n",
    "            )\n",
    "\n",
    "param_dist = {\n",
    "    \"n_estimators\": [100, 200],\n",
    "    \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "    \"max_depth\": [3, 4, 7],\n",
    "    \"min_child_weight\": [1, 5, 10],\n",
    "    \"gamma\": [0, 1, 5],\n",
    "    \"subsample\": [0.6, 0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.6, 0.8, 1.0],\n",
    "    \"scale_pos_weight\": [1,3,3.5,2.5]  # useful if data is imbalanced\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=5,               # <-- control number of parameter combinations\n",
    "    scoring=\"roc_auc\",\n",
    "    cv=cv,\n",
    "    verbose=2,\n",
    "    random_state=42\n",
    ")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "best_model = random_search.best_estimator_\n",
    "print(\"Best parameters:\", random_search.best_params_)\n",
    "print(\"Best CV score:\", random_search.best_score_)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. Evaluation on Test Set\n",
    "# ---------------------------------------------------------\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Classification Report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4. Feature Importance\n",
    "# ---------------------------------------------------------\n",
    "plt.figure(figsize=(10,6))\n",
    "plot_importance(best_model, importance_type=\"weight\")  # \"gain\" is also common\n",
    "plt.title(\"Feature Importance (XGBoost)\")\n",
    "plt.show()\n"
   ],
   "id": "c4cb8f990f8514f3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ],
   "id": "2b8c69ca7a947147",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
